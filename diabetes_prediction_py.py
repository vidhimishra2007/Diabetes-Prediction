# -*- coding: utf-8 -*-
"""Diabetes_Prediction.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dmoWD7i4ttmQn2JZrSmPbn0kQbBe_XmL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
sns.set()

df=pd.read_csv('diabetes.csv')
df.head()

df.columns

df.info()

df.describe()

df.describe().T

df.isnull().head(10)

df.isnull().sum()

"""**Handling Missing Values**"""

df_copy = df.copy(deep=True)
df_copy[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df_copy[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)

print(df_copy.isnull().sum())

df.hist(figsize=(15,15))

df_copy['Glucose'].fillna(df_copy['Glucose'].mean(), inplace=True)
df_copy['BloodPressure'].fillna(df_copy['BloodPressure'].mean(), inplace=True)
df_copy['SkinThickness'].fillna(df_copy['SkinThickness'].median(), inplace=True)
df_copy['Insulin'].fillna(df_copy['Insulin'].median(), inplace=True)
df_copy['BMI'].fillna(df_copy['BMI'].median(), inplace=True)

df_copy.hist(figsize=(15,15))

import missingno as msno
msno.bar(df)

color_wheel = {1: "#808080", 2: "#7bc043"} ##808080(a shade of grey) → Assigned to 1. #7bc043 (a shade of green) → Assigned to 2.
colors = df["Outcome"].map(lambda x: color_wheel.get(x + 1)) #Lambda function: lambda x: color_wheel.get(x + 1)
#Function applied: Adds 1 to each Outcome value and retrieves the corresponding color from color_wheel.
#Why? Because the color_wheel dictionary uses keys 1 and 2 (not 0 and 1).
#Result: Each Outcome value is converted into a color.
print(df.Outcome.value_counts()) #Printing Value Counts
p = df.Outcome.value_counts().plot(kind="bar",color=colors.unique()) #.unique() ensures only the distinct colors are used for bars (instead of duplicating colors).

plt.subplot(121)
sns.distplot(df['Insulin'])
plt.subplot(122)
df['Insulin'].plot.box(figsize=(16, 5))
plt.show()

plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, cmap='RdYlGn')

df_copy.head()

from sklearn.preprocessing import StandardScaler

sc_X = StandardScaler()
X = pd.DataFrame(sc_X.fit_transform(df_copy.drop(['Outcome'], axis=1)),
columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'])

X.head()

y = df_copy.Outcome
y.head()

"""**Split Dataset into Features and target**"""

X=df.drop('Outcome', axis=1) #Features
y=df['Outcome'] #Target

"""**Train-Test Split**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7)

"""**Decision Tree**"""

dt_model=DecisionTreeClassifier()
dt_model.fit(X_train,y_train)

"""**Model Prediction**"""

y_pred=dt_model.predict(X_test)
dt_training_accuracy=dt_model.score(X_train,y_train)
dt_testing_accuracy=dt_model.score(X_test,y_test)
dt_accuracy=accuracy_score(y_test, y_pred)

"""**Evaluate The Model**"""

print("Accuracy:", dt_accuracy)
print("Training Accuracy:",dt_training_accuracy )
print("Testing Accuracy:",dt_testing_accuracy )

#Visualize Model Accuracy Bar Chart
plt.bar(['Training Accuracy','Testing Accuracy'],[dt_training_accuracy, dt_testing_accuracy])
plt.ylabel('Accuracy')
plt.title('Decision Tree Model Accuracy')
plt.show()
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Visualize Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='YlGnBu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Decision Tree Confusion Matrix')
plt.show()

"""**Feature Importance**"""

importances = dt_model.feature_importances_
feature_names = X.columns

feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp_df.sort_values(by='Importance', ascending=False, inplace=True)

sns.barplot(x='Importance', y='Feature', data=feat_imp_df)
plt.title('Feature Importance')
plt.show()

"""**Random Forest Classifier**"""

rf_model=RandomForestClassifier(n_estimators=200)
rf_model.fit(X_train, y_train)

"""**Model Predictions**"""

y_pred=rf_model.predict(X_test)
rf_training_accuracy=rf_model.score(X_train,y_train)
rf_testing_accuracy=rf_model.score(X_test,y_test)
rf_accuracy=accuracy_score(y_test, y_pred)

"""**Evaluate the Model**"""

print("Accuracy:", rf_accuracy)
print("Training Accuracy:",rf_training_accuracy )
print("Testing Accuracy:",rf_testing_accuracy )

#Visualize Model Accuracy Bar Chart
plt.bar(['Training Accuracy','Testing Accuracy'],[rf_training_accuracy, rf_testing_accuracy])
plt.ylabel('Accuracy')
plt.title('Random Forest Model Accuracy')
plt.show()

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Optional: Visualize Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='YlGnBu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Random Forest Confusion Matrix')
plt.show()

"""**Feature Importance**"""

importances = rf_model.feature_importances_
feature_names = X.columns

feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp_df.sort_values(by='Importance', ascending=False, inplace=True)

sns.barplot(x='Importance', y='Feature', data=feat_imp_df)
plt.title('Feature Importance')
plt.show()

"""**XGBoost Classifier**"""

from xgboost import XGBClassifier
xgb_model=XGBClassifier()
xgb_model.fit(X_train, y_train)

"""**Model Prediction**"""

y_pred=xgb_model.predict(X_test)
xgb_training_accuracy=xgb_model.score(X_train,y_train)
xgb_testing_accuracy=xgb_model.score(X_test,y_test)
xgb_accuracy=accuracy_score(y_test,y_pred)

"""**Evaluate The Model**"""

print("Accuracy:",xgb_accuracy)
print("Training Accuracy:",xgb_training_accuracy)
print("Testing Accuracy:",xgb_testing_accuracy)

#Visualize Model Accuracy Bar Chart
plt.bar(['Training Accuracy','Testing Accuracy'],[xgb_training_accuracy, xgb_testing_accuracy])
plt.ylabel('Accuracy')
plt.title('XGBoost Classifier Model Accuracy')
plt.show()

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Optional: Visualize Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='YlGnBu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('XGBOOST Classifier Confusion Matrix')
plt.show()

"""**Feature importance**"""

importances = xgb_model.feature_importances_
feature_names = X.columns

feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp_df.sort_values(by='Importance', ascending=False, inplace=True)

sns.barplot(x='Importance', y='Feature', data=feat_imp_df)
plt.title('Feature Importance')
plt.show()

"""**Support Vector Machine**"""

from sklearn.svm import SVC
svm_model=SVC()
svm_model.fit(X_train, y_train)

"""**Model Prediction**"""

y_pred=svm_model.predict(X_test)
svm_training_accuracy=svm_model.score(X_train, y_train)
svm_testing_accuracy=svm_model.score(X_test, y_test)
svm_accuracy=accuracy_score(y_test, y_pred)

"""**Evaluate The Model**"""

print("Accuracy",svm_accuracy)
print("Training Accuracy",svm_training_accuracy)
print("Testing Accuracy",svm_testing_accuracy)

#Visualize Model Accuracy Bar Chart
plt.bar(['Training Accuracy','Testing Accuracy'],[svm_training_accuracy, svm_testing_accuracy])
plt.ylabel('Accuracy')
plt.title('SVM Model Accuracy')
plt.show()

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Optional: Visualize Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='YlGnBu')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('SVM Confusion Matrix')
plt.show()

"""**Accuracy Comparison**"""

accuracy_data = {
    'Algorithm': ['Decision Tree', 'Random Forest', 'XGBoost', 'SVM'],
    'Training Accuracy': [dt_training_accuracy, rf_training_accuracy, xgb_training_accuracy, svm_training_accuracy],
    'Testing Accuracy': [dt_testing_accuracy, rf_testing_accuracy, xgb_testing_accuracy, svm_testing_accuracy],
    'Overall Accuracy': [dt_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy]
}
#accuracy_data: This dictionary stores the algorithm names and their corresponding training, testing, and overall accuracies.

accuracy_df = pd.DataFrame(accuracy_data)
#accuracy_df:This converts the accuracy_data dictionary into a DataFrame for easier handling and plotting.

# Plotting the accuracy comparison
fig, ax = plt.subplots(figsize=(10, 6))
#It creates a figure and axes for the plot with a specified size.

bar_width = 0.25
#Defines the width of the bars in the bar chart.
index = np.arange(len(accuracy_df)) #creates an index for positioning the bars.

bar1 = ax.bar(index - bar_width, accuracy_df['Training Accuracy'], bar_width, label='Training Accuracy', color='skyblue')
bar2 = ax.bar(index, accuracy_df['Testing Accuracy'], bar_width, label='Testing Accuracy', color='lightcoral')
bar3 = ax.bar(index + bar_width, accuracy_df['Overall Accuracy'], bar_width, label='Overall Accuracy', color='lightgreen')
#It generates three sets of bars for each algorithm: one for training accuracy, one for testing accuracy, and one for overall accuracy. Each set of bars is offset slightly to appear side-by-side for each algorithm.

ax.set_xlabel('Algorithm')
ax.set_ylabel('Accuracy')
ax.set_title('Accuracy Comparison of Different Algorithms')
ax.set_xticks(index)
ax.set_xticklabels(accuracy_df['Algorithm'])
ax.legend() #Includes a legend to identify which color corresponds to which accuracy type (training, testing, or overall).

# Add accuracy values on top of bars
#The add_value_labels function is defined and called to display the exact accuracy values on top of each bar.
def add_value_labels(ax, bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2f}',
                ha='center', va='bottom')

add_value_labels(ax, bar1)
add_value_labels(ax, bar2)
add_value_labels(ax, bar3)


plt.ylim(0, 1.1) # Set y-axis limit for better visualization
plt.tight_layout() #Uses plt.tight_layout() to prevent labels from overlapping.
plt.show()

import pickle
with open("DP_model.pkl", "wb") as f:
    pickle.dump(rf_model, f)
print("Model saved as DP_model.pkl!")

with open("DP_model.pkl", "rb") as f:
    model = pickle.load(f)

# Example prediction
sample_data = np.array([[0, 137, 40, 35, 168, 43.1, 2.228, 33]])  # Example input
prediction = model.predict(sample_data)

if prediction == 0:
    print("The person is not diabetic.")
else:
    print("The person is diabetic.")
print("Prediction:", prediction)  # Output: 0 (No Diabetes) or 1 (Diabetes)

# Another Example prediction
sample_data = np.array([[10, 101, 76, 48, 180, 32.9, 0.171, 63]])  # Example input
prediction = model.predict(sample_data)

if prediction == 0:
    print("The person is not diabetic.")
else:
    print("The person is diabetic.")
print("Prediction:", prediction) # Output: 0 (No Diabetes) or 1 (Diabetes)

# Another Example prediction
sample_data = np.array([[0,99,62,20,84,25.2,0.351,22]])  # Example input
prediction = model.predict(sample_data)

if prediction == 0:
    print("The person is not diabetic.")
else:
    print("The person is diabetic.")
print("Prediction:", prediction) # Output: 0 (No Diabetes) or 1 (Diabetes)

# Another Example prediction
sample_data = np.array([[3,138,80,33,140,32.9,0.610,31]])  # Example input
prediction = model.predict(sample_data)

if prediction == 0:
    print("The person is not diabetic.")
else:
    print("The person is diabetic.")
print("Prediction:", prediction) # Output: 0 (No Diabetes) or 1 (Diabetes)